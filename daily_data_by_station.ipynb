{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_station_meta(station_number):\n",
    "    station_meta = dict()\n",
    "    station_header_file = f'data/hly{station_number}_header.csv'\n",
    "    df_header = pd.read_csv(station_header_file)\n",
    "    for row in df_header[df_header.columns[0]]:\n",
    "        if 'Latitude' in row:\n",
    "            split_vals = row.split(',')\n",
    "            station_meta['latitude'] = float(split_vals[0].replace('Latitude:',''))\n",
    "            station_meta['longitude'] = float(split_vals[-1].replace('Longitude:',''))\n",
    "    return station_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hly1075.gz.parquet',\n",
       " 'hly1175.gz.parquet',\n",
       " 'hly1275.gz.parquet',\n",
       " 'hly1375.gz.parquet',\n",
       " 'hly1475.gz.parquet',\n",
       " 'hly175.gz.parquet',\n",
       " 'hly1775.gz.parquet',\n",
       " 'hly1875.gz.parquet',\n",
       " 'hly1975.gz.parquet',\n",
       " 'hly2075.gz.parquet',\n",
       " 'hly2175.gz.parquet',\n",
       " 'hly2275.gz.parquet',\n",
       " 'hly2375.gz.parquet',\n",
       " 'hly275.gz.parquet',\n",
       " 'hly3723.gz.parquet',\n",
       " 'hly375.gz.parquet',\n",
       " 'hly3904.gz.parquet',\n",
       " 'hly518.gz.parquet',\n",
       " 'hly532.gz.parquet',\n",
       " 'hly575.gz.parquet',\n",
       " 'hly675.gz.parquet',\n",
       " 'hly775.gz.parquet',\n",
       " 'hly875.gz.parquet']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_files = [file for file in os.listdir('data/') if 'gz.parquet' in file and ('hly' in file or 'dly' in file)]\n",
    "raw_data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get station info df\n",
    "df_station_details = pd.read_csv('data/station_details.csv')\n",
    "df_station_details = df_station_details.set_index('Station Number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "data/hly1075.gz.parquet\n",
      "(247992, 4)\n",
      "(11139, 19)\n",
      "(11139, 19)\n",
      "data/hly1175.gz.parquet\n",
      "(127080, 4)\n",
      "(5268, 19)\n",
      "(16407, 19)\n",
      "data/hly1275.gz.parquet\n",
      "(100824, 3)\n",
      "(4334, 15)\n",
      "(20741, 19)\n",
      "data/hly1375.gz.parquet\n",
      "(100823, 4)\n",
      "(4566, 19)\n",
      "(25307, 19)\n",
      "data/hly1475.gz.parquet\n",
      "(100080, 4)\n",
      "(4165, 19)\n",
      "(29472, 19)\n",
      "data/hly175.gz.parquet\n",
      "(112080, 3)\n",
      "(5175, 15)\n",
      "(34647, 19)\n",
      "data/hly1775.gz.parquet\n",
      "(127128, 4)\n",
      "(5295, 19)\n",
      "(39942, 19)\n",
      "data/hly1875.gz.parquet\n",
      "(70248, 4)\n",
      "(2928, 19)\n",
      "(42870, 19)\n",
      "data/hly1975.gz.parquet\n",
      "(100128, 4)\n",
      "(4588, 19)\n",
      "(47458, 19)\n",
      "data/hly2075.gz.parquet\n",
      "(185347, 4)\n",
      "(6703, 19)\n",
      "(54161, 19)\n",
      "data/hly2175.gz.parquet\n",
      "(267276, 4)\n",
      "(11139, 19)\n",
      "(65300, 19)\n",
      "data/hly2275.gz.parquet\n",
      "(267312, 4)\n",
      "(11139, 19)\n",
      "(76439, 19)\n",
      "data/hly2375.gz.parquet\n",
      "(267313, 4)\n",
      "(11139, 19)\n",
      "(87578, 19)\n",
      "data/hly275.gz.parquet\n",
      "(130416, 4)\n",
      "(5448, 19)\n",
      "(93026, 19)\n",
      "data/hly3723.gz.parquet\n",
      "(267313, 4)\n",
      "(11139, 19)\n",
      "(104165, 19)\n",
      "data/hly375.gz.parquet\n",
      "(139512, 4)\n",
      "(5802, 19)\n",
      "(109967, 19)\n",
      "data/hly3904.gz.parquet\n",
      "(267313, 4)\n",
      "(11139, 19)\n",
      "(121106, 19)\n",
      "data/hly518.gz.parquet\n",
      "(267313, 4)\n",
      "(11139, 19)\n",
      "(132245, 19)\n",
      "data/hly532.gz.parquet\n",
      "(267313, 4)\n",
      "(11139, 19)\n",
      "(143384, 19)\n",
      "data/hly575.gz.parquet\n",
      "(139512, 4)\n",
      "(5805, 19)\n",
      "(149189, 19)\n",
      "data/hly675.gz.parquet\n",
      "(125640, 4)\n",
      "(5295, 19)\n",
      "(154484, 19)\n",
      "data/hly775.gz.parquet\n",
      "(132960, 4)\n",
      "(5540, 19)\n",
      "(160024, 19)\n",
      "data/hly875.gz.parquet\n",
      "(267313, 4)\n",
      "(11139, 19)\n",
      "(171163, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amaguire\\AppData\\Local\\Continuum\\anaconda3\\envs\\ami\\lib\\site-packages\\pyarrow\\pandas_compat.py:114: FutureWarning: A future version of pandas will default to `skipna=True`. To silence this warning, pass `skipna=True|False` explicitly.\n",
      "  result = infer_dtype(pandas_collection)\n"
     ]
    }
   ],
   "source": [
    "df_processed = pd.DataFrame()\n",
    "for file in raw_data_files:\n",
    "    print(df_processed.shape)\n",
    "    station_number = int(file.replace('.gz','').replace('.parquet','').replace('hly','').replace('dly',''))\n",
    "    station_file = f'data/{file}'\n",
    "    station_meta = get_station_meta(station_number)\n",
    "    print(station_file)\n",
    "    df = pd.read_parquet(station_file,columns=['temp','rain','wdsp','rhum'])\n",
    "    print(df.shape)\n",
    "    df = df.dropna()\n",
    "    df = df.set_index(pd.to_datetime(df.index))\n",
    "    df = df.resample('1d').apply(['mean','max','min','std'])\n",
    "    df = df.round(2)\n",
    "    df.columns = ['_'.join(col).strip() for col in df.columns.values]\n",
    "    df['station_number'] = station_number\n",
    "    df['latitide'] = station_meta['latitude']\n",
    "    df['longitude'] = station_meta['longitude']\n",
    "    #df['latitide'] = df_station_details.iloc[station_number]['Latitude']\n",
    "    #df['longitude'] = df_station_details.iloc[station_number]['Longitude']\n",
    "    print(df.shape)\n",
    "    df_processed = df_processed.append(df)\n",
    "print(df_processed.shape)\n",
    "df_processed.to_parquet('data/data_daily_by_station.gz.parquet',compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
